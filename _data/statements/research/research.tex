% --------------- 12 POINT FONT -------------------------------
\documentclass[12pt]{article}
% --------------- 10 POINT FONT FOR CAPTIONS ------------------
\usepackage[font=footnotesize]{caption}
% --------------- New TIMES Roman FONT -------------------------------
\usepackage{times}
% --------------- 1 INCH MARGINS ------------------------------
\usepackage[margin=1in]{geometry}
% --------------- LINE SPACING --------------------------------
\usepackage{setspace}
\singlespacing
%\doublespacing
% --------------- SMALL SECTION TITLES ------------------------
\usepackage[tiny,compact]{titlesec}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage[square,sort,comma,numbers]{natbib}
\setlength{\bibsep}{0pt}
\bibliographystyle{ieeetr}
\usepackage[
activate = {true},
kerning  = true,
spacing  = true,
factor   = 1000,
stretch  = 30,
shrink   = 30,
]{microtype}
\pagestyle{empty}

\titleformat{\section}[display]%
{\normalfont\bfseries}
{}{0pt}{}
\titlespacing*{\section}{0pt}{-1.3em}{0pt}

\begin{document}
\begin{center}
  {\large \textbf{Statement of Research Interests}} \\[0.1em]
  {Constantinos Chamzas}
\end{center}

My overall aim as a researcher is to help in bringing robots into real-world manipulation problems which are potentially dangerous or mundane for humans.
Over the years, the field of robotics has developed several theoretically sound algorithms to enable robotic manipulation.
However, most of them are either too computationally expensive or rely on complete environment information that is not readily available in reality. 
Today, learning-based methods aim to bridge this gap and have found widespread success in robotics, but most methodologies usually forego the theoretical guarantees of the classical methods.
My work lies in combining classical robotic manipulation algorithms with learning techniques to achieve the best of both worlds. 

A particular area of focus is leveraging a robot's past experience to efficiently solve complex robotic motion planning problems across a wide range of scenarios.
Examples include solving challenging planning problems by learning local sampling distributions with few training examples \cite{chamzas2019using-local-experiences-for-global-motion-planning} even in partially observable environments \cite{chamzas2021-learn-sampling}, by adapting retrieved paths on the fly \cite{pairet2021-path-planning-for-manipulation} and by guiding planning in constraint manifolds \cite{kingston2021experience-foliations}. Additionally, since learning for motion planning is an emerging field, I also focused in tools
for tuning \cite{moll2021hyperplan} or benchmarking \cite{chamzas2022-motionbenchmaker} planning algorithms. 

Potential future research avenues include leveraging learning methods for the field of Task and Motion Planning (TAMP).
Besides improving the efficiency of TAMP methods, I am interested in the problem of visual grounding and symbol learning.
In others words, developing methods that extract plannable (symbolic) representations from images suitable for classical TAMP planners.
Some preliminary work in this area \cite{chamzas2020rep-learning, chamzas2022-reconstruction} aims to leverage simple task priors to learn robust state-representations from images to enable visual task planning.    
Recent work from the NVIDIA labs \cite{sornet, reactive, nerp, structformer} is also focusing on visual task planning problems. 
However, two open problems that still remain are a) extracting symbolic plannable representations directly from images through unsupervised interaction and b) learning compositional predictive models from images suitable for interleaved task and motion planning such as PDDLStream.   

\vspace{2em}
\footnotesize
\bibliography{papers.bib, extra.bib}
\end{document}
