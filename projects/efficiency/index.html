<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Planning Efficiency | ELPIS Lab </title> <meta name="author" content="ELPIS Lab"> <meta name="description" content="Enchance planners efficiency."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A4%96&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://elpislab.org/projects/efficiency/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> ELPIS Lab </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">People </a> </li> <li class="nav-item "> <a class="nav-link" href="/research/">Research </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Code </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/join/">Join </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Planning Efficiency</h1> <p class="post-description">Enchance planners efficiency.</p> </header> <article> <p>Efficient computation of robot motion trajectories is crucial for deploying robots in time-constrained applications. Simple tasks like picking an object from a deep shelf remain challenging due to narrow navigation areas, often requiring minutes of computation. Leveraging past experiences can significantly reduce planning time, but effectively combining planning and learning is complex. ELPIS lab conducts research in this area aiming to advance the efficiency of motion planners in realistic scenarios. Additionally, the Lab is also interested in creating community accepted datasets to help evaluated objectively the progress in the field.</p> <div class="publications"> <left> <h2><span style="color: var(--global-theme-color)"> Relevant Publications </span></h2> </left> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">HSCC</abbr> </div> <div id="10.1145/3716863.3718041" class="col-sm-10"> <div class="title">Multi-layer Motion Planning with Kinodynamic and Spatio-Temporal Constraints</div> <div class="author"> J. Chatrola, A. Ajith, K. Leahy, and <em>C Chamzas</em> </div> <div class="periodical"> <em>In Proceedings of the 28th ACM International Conference on Hybrid Systems: Computation and Control,</em> 2025 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/ajith2025multilayerplanning.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> <a href="https://github.com/elpis-lab/LG-SST-STL" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a> <a href="https://dl.acm.org/doi/10.1145/3716863.3718041" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">URL</a> </div> <div class="abstract hidden"> <p>We propose a novel, multi-layered planning approach for computing paths that satisfy both kinodynamic and spatiotemporal constraints. Our three-part framework first establishes potential sequences to meet spatial constraints, using them to calculate a geometric lead path. This path then guides an asymptotically optimal sampling-based kinodynamic planner, which minimizes an STL-robustness cost to jointly satisfy spatiotemporal and kinodynamic constraints. In our experiments, we test our method with a velocity-controlled Ackerman-car model and demonstrate significant efficiency gains compared to prior art. Additionally, our method is able to generate complex path maneuvers, such as crossovers, something that previous methods had not demonstrated.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1145/3716863.3718041</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chatrola, Jeel and Ajith, Abhiroop and Leahy, Kevin and Chamzas, Constantinos}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Multi-layer Motion Planning with Kinodynamic and Spatio-Temporal Constraints}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400715044}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://dl.acm.org/doi/10.1145/3716863.3718041}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3716863.3718041}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 28th ACM International Conference on Hybrid Systems: Computation and Control}</span><span class="p">,</span>
  <span class="na">articleno</span> <span class="p">=</span> <span class="s">{5}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{7}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Motion Planning, Robotics, Signal Temporal Logic}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Irvine, CA, USA}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{HSCC '25}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge"><a href="https://www.ieee-ras.org/conferences-workshops/financially-co-sponsored/iros" target="_blank" rel="external nofollow noopener">IROS</a></abbr> </div> <div id="zhong20240expansion-grr" class="col-sm-10"> <div class="title">Expansion-GRR: Efficient Generation of Smooth Global Redundancy Resolution Roadmaps</div> <div class="author"> Z. Zhong, Z. Li, and <em>C Chamzas</em> </div> <div class="periodical"> <em>In IEEE/RSJ International Conference on Intelligent Robots and Systems,</em> 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/zhong2024-expansion-grr.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> <a href="https://github.com/elpis-lab/Expansion-GRR" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a> <a href="https://arxiv.org/abs/2405.13770" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">URL</a> </div> <div class="abstract hidden"> <p>Global redundancy resolution (GRR) roadmaps is a novel concept in robotics that facilitates the mapping from task space paths to configuration space paths in a legible, predictable and repeatable way. Such roadmaps could find widespread utility in applications such as safe teleoperation, consistent path planning, and motion primitives generation. However, previous methods to compute GRR roadmaps often necessitate a lengthy computation time and produce non-smooth paths, limiting their practical efficacy. To address this challenge, we introduce a novel method Expansion-GRR that leverages efficient configuration space projections and enables rapid generation of smooth roadmaps that satisfy the task constraints. Additionally, we propose a simple multi-seed strategy that further enhances the final quality. We conducted experiments in simulation with a 5-link planar manipulator and a Kinova arm. We were able to generate the Expansion-GRR roadmaps up to 2 orders of magnitude faster while achieving higher smoothness. We also demonstrate the utility of the GRR roadmaps in teleoperation tasks where our method outperformed prior methods and reactive IK solvers in terms of success rate and solution quality</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zhong20240expansion-grr</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhong, Zhuoyun and Li, Zhi and Chamzas, Constantinos}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Expansion-GRR: Efficient Generation of Smooth Global Redundancy Resolution Roadmaps}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2405.13770}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE/RSJ International Conference on Intelligent Robots and Systems}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge"><a href="https://www.annualreviews.org/content/journals/control" target="_blank" rel="external nofollow noopener">AR</a></abbr> </div> <div id="orthey2024-review-sampling" class="col-sm-10"> <div class="title">Sampling-Based Motion Planning: A Comparative Review</div> <div class="author"> A. Orthey, <em>C. Chamzas</em>, and L. Kavraki </div> <div class="periodical"> <em>Annual Review of Control, Robotics, and Autonomous Systems,</em> 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/orthey2024-review-sampling.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> <a href="https://doi.org/10.1146/annurev-control-061623-094742" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">URL</a> </div> <div class="abstract hidden"> <p>Sampling-based motion planning is one of the fundamental paradigms to generate robot motions, and a cornerstone of robotics research. This comparative review provides an up-to-date guideline and reference manual for the use of sampling-based motion planning algorithms. This includes a history of motion planning, an overview about the most successful planners, and a discussion on their properties. It is also shown how planners can handle special cases and how extensions of motion planning can be accommodated. To put sampling-based motion planning into a larger context, a discussion of alternative motion generation frameworks is presented which highlights their respective differences to sampling-based motion planning. Finally, a set of sampling-based motion planners are compared on 24 challenging planning problems. This evaluation gives insights into which planners perform well in which situations and where future research would be required. This comparative review thereby provides not only a useful reference manual for researchers in the field, but also a guideline for practitioners to make informed algorithmic decisions.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">orthey2024-review-sampling</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Orthey, Andreas and Chamzas, Constantinos and Kavraki, Lydia E.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Sampling-Based Motion Planning: A Comparative Review}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Annual Review of Control, Robotics, and Autonomous Systems}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{7}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{285-310}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1146/annurev-control-061623-094742}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1146/annurev-control-061623-094742}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge"><a href="https://www.ieee-ras.org/publications/ra-l" target="_blank" rel="external nofollow noopener">RAL</a></abbr> </div> <div id="lee2022-apes" class="col-sm-10"> <div class="title">Adaptive Experience Sampling for Motion Planning using the Generator-Critic Framework</div> <div class="author"> Y. Lee, <em>C. Chamzas</em>, and L. E. Kavraki </div> <div class="periodical"> <em>IEEE Robotics and Automation Letters,</em> 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/lee2022-apes.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> <a href="https://dx.doi.org/10.1109/LRA.2022.3191803" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">URL</a> </div> <div class="abstract hidden"> <p>Sampling-based motion planners are widely used for motion planning with high-dof robots. These planners generally rely on a uniform distribution to explore the search space. Recent work has explored learning biased sampling distributions to improve the time efficiency of these planners. However, learning such distributions is challenging, since there is no direct connection between the choice of distributions and the performance of the downstream planner. To alleviate this challenge, this paper proposes APES, a framework that learns sampling distributions optimized directly for the planner’s performance. This is done using a critic, which serves as a differentiable surrogate objective modeling the planner’s performance - thus allowing gradients to circumvent the non-differentiable planner. Leveraging the differentiability of the critic, we train a generator, which outputs sampling distributions optimized for the given problem instance. We evaluate APES on a series of realistic and challenging high-dof manipulation problems in simulation. Our experimental results demonstrate that APES can learn high-quality distributions that improve planning performance more than other biased sampling baselines.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">lee2022-apes</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Adaptive Experience Sampling for Motion Planning using the Generator-Critic Framework}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Robotics and Automation Letters}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{7}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{9437-9444}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2377-3766}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/LRA.2022.3191803}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Lee, Yiyuan and Chamzas, Constantinos and E. Kavraki, Lydia}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://dx.doi.org/10.1109/LRA.2022.3191803}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge"><a href="https://www.ieee-ras.org/conferences-workshops/fully-sponsored/icra" target="_blank" rel="external nofollow noopener">ICRA</a></abbr> </div> <div id="chamzas2022-learn-retrieve" class="col-sm-10"> <div class="title">Learning to Retrieve Relevant Experiences for Motion Planning</div> <div class="author"> <em>C. Chamzas</em>, A. Cullen, A. Shrivastava, and L. E. Kavraki </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation,</em> 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/chamzas2022-learn-retrieve.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> <a href="https://doi.org/10.1109/ICRA46639.2022.9812076" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">URL</a> <a href="https://youtu.be/6E2BXmAdAvM" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">TALK</a> </div> <div class="abstract hidden"> <p>Recent work has demonstrated that motion planners’ performance can be significantly improved by retrieving past experiences from a database. Typically, the experience database is queried for past similar problems using a similarity function defined over the motion planning problems. However, to date, most works rely on simple hand-crafted similarity functions and fail to generalize outside their corresponding training dataset. To address this limitation, we propose (FIRE), aframework that extracts local representations of planning problems and learns a similarity function over them. To generate the training data we introduce a novel self-supervised method that identifies similar and dissimilar pairs of local primitives from past solution paths. With these pairs, a Siamese network is trained with the contrastive loss and the similarity function is realized in the network’s latent space. We evaluate FIRE on an 8-DOF manipulator in five categories of motion planning problems with sensed environments. Our experiments show that FIRE retrieves relevant experiences which can informatively guide sampling-based planners even in problems outside its training distribution, outperforming other baselines.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">chamzas2022-learn-retrieve</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chamzas, Constantinos and Cullen, Aedan and Shrivastava, Anshumali and E. Kavraki, Lydia}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Robotics and Automation}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{7233--7240}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICRA46639.2022.9812076}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning to Retrieve Relevant Experiences for Motion Planning}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1109/ICRA46639.2022.9812076}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge"><a href="https://www.ieee-ras.org/publications/ra-l" target="_blank" rel="external nofollow noopener">RAL</a></abbr> </div> <div id="chamzas2022-motion-bench-maker" class="col-sm-10"> <div class="title">MotionBenchMaker: A Tool to Generate and Benchmark Motion Planning Datasets</div> <div class="author"> <em>C. Chamzas</em>, C. Quintero-Peña, Z. Kingston, A. Orthey, D. Rakita, M. Gleicher, M. Toussaint, and L. E. Kavraki </div> <div class="periodical"> <em>IEEE Robotics and Automation Letters,</em> 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/chamzas2022-motion-bench-maker.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> <a href="https://github.com/KavrakiLab/motion_bench_maker" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a> <a href="https://dx.doi.org/10.1109/LRA.2021.3133603" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">URL</a> <a href="https://youtu.be/t96Py0QX0NI" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">video</a> <a href="https://youtu.be/ggRmKPt7IP8" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">TALK</a> </div> <div class="abstract hidden"> <p>Recently, there has been a wealth of development in motion planning for robotic manipulationnew motion planners are continuously proposed, each with its own unique set of strengths and weaknesses. However, evaluating these new planners is challenging, and researchers often create their own ad-hoc problems for benchmarking, which is time-consuming, prone to bias, and does not directly compare against other state-of-the-art planners. We present MotionBenchMaker, an open-source tool to generate benchmarking datasets for realistic robot manipulation problems. MotionBenchMaker is designed to be an extensible, easy-to-use tool that allows users to both generate datasets and benchmark them by comparing motion planning algorithms. Empirically, we show the benefit of using MotionBenchMaker as a tool to procedurally generate datasets which helps in the fair evaluation of planners. We also present a suite of over 40 prefabricated datasets, with 5 different commonly used robots in 8 environments, to serve as a common ground for future motion planning research.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">chamzas2022-motion-bench-maker</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{MotionBenchMaker: A Tool to Generate and Benchmark Motion Planning Datasets}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{7}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{882–889}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2377-3766}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/LRA.2021.3133603}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Robotics and Automation Letters}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chamzas, Constantinos and Quintero-Pe{\~n}a, Carlos and Kingston, Zachary and Orthey, Andreas and Rakita, Daniel and Gleicher, Michael and Toussaint, Marc and E. Kavraki, Lydia}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://dx.doi.org/10.1109/LRA.2021.3133603}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge"><a href="https://www.ieee-ras.org/conferences-workshops/financially-co-sponsored/iros" target="_blank" rel="external nofollow noopener">IROS</a></abbr> </div> <div id="kingston2021experience-foliations" class="col-sm-10"> <div class="title">Using Experience to Improve Constrained Planning on Foliations for Multi-Modal Problems</div> <div class="author"> Z. Kingston, <em>C. Chamzas</em>, and L. E. Kavraki </div> <div class="periodical"> <em>In IEEE/RSJ International Conference on Intelligent Robots and Systems,</em> 2021 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/kingston2021experience-foliations.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> <a href="https://doi.org/10.1109/IROS51168.2021.9636236" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">URL</a> </div> <div class="abstract hidden"> <p>Many robotic manipulation problems are multi-modal—they consist of a discrete set of mode families (e.g., whether an object is grasped or placed) each with a continuum of parameters (e.g., where exactly an object is grasped). Core to these problems is solving single-mode motion plans, i.e., given a mode from a mode family (e.g., a specific grasp), find a feasible motion to transition to the next desired mode. Many planners for such problems have been proposed, but complex manipulation plans may require prohibitively long computation times due to the difficulty of solving these underlying single-mode problems. It has been shown that using experience from similar planning queries can significantly improve the efficiency of motion planning. However, even though modes from the same family are similar, they impose different constraints on the planning problem, and thus experience gained in one mode cannot be directly applied to another. We present a new experience-based framework, ALEF , for such multi-modal planning problems. ALEF learns using paths from single-mode problems from a mode family, and applies this experience to novel modes from the same family. We evaluate ALEF on a variety of challenging problems and show a significant improvement in the efficiency of sampling-based planners both in isolation and within a multi-modal manipulation planner.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">kingston2021experience-foliations</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kingston, Zachary and Chamzas, Constantinos and E. Kavraki, Lydia}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE/RSJ International Conference on Intelligent Robots and Systems}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Using Experience to Improve Constrained Planning on Foliations for Multi-Modal Problems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{6922-6927}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/IROS51168.2021.9636236}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1109/IROS51168.2021.9636236}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge"><a href="https://www.ieee-ras.org/conferences-workshops/financially-co-sponsored/iros" target="_blank" rel="external nofollow noopener">IROS</a></abbr> </div> <div id="moll2021hyperplan" class="col-sm-10"> <div class="title">HyperPlan: A Framework for Motion Planning Algorithm Selection and Parameter Optimization</div> <div class="author"> M. Moll, <em>C. Chamzas</em>, Z. Kingston, and L. E. Kavraki </div> <div class="periodical"> <em>In IEEE/RSJ International Conference on Intelligent Robots and Systems,</em> 2021 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/moll2021hyperplan.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> <a href="https://github.com/KavrakiLab/hyperplan" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a> <a href="https://doi.org/10.1109/IROS51168.2021.9636651" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">URL</a> </div> <div class="abstract hidden"> <p>Over the years, many motion planning algorithms have been proposed. It is often unclear which algorithm might be best suited for a particular class of problems. The problem is compounded by the fact that algorithm performance can be highly dependent on parameter settings. This paper shows that hyperparameter optimization is an effective tool in both algorithm selection and parameter tuning over a given set of motion planning problems. We present different loss functions for optimization that capture different notions of optimality. The approach is evaluated on a broad range of scenes using two different manipulators, a Fetch and a Baxter. We show that optimized planning algorithm performance significantly improves upon baseline performance and generalizes broadly in the sense that performance improvements carry over to problems that are very different from the ones considered during optimization.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">moll2021hyperplan</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Moll, Mark and Chamzas, Constantinos and Kingston, Zachary and E. Kavraki, Lydia}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE/RSJ International Conference on Intelligent Robots and Systems}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{HyperPlan: A Framework for Motion Planning Algorithm Selection and Parameter Optimization}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2511-2518}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/IROS51168.2021.9636651}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1109/IROS51168.2021.9636651}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge"><a href="https://www.ieee-ras.org/conferences-workshops/fully-sponsored/icra" target="_blank" rel="external nofollow noopener">ICRA</a></abbr> </div> <div id="chamzas2021-learn-sampling" class="col-sm-10"> <div class="title">Learning Sampling Distributions Using Local 3D Workspace Decompositions for Motion Planning in High Dimensions</div> <div class="author"> <em>C. Chamzas</em>, Z. Kingston, C. Quintero-Peña, A. Shrivastava, and L. E. Kavraki </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation,</em> 2021 <br> <strong style="color: var(--global-theme-color)"> (Top-4 finalist for best paper in Cognitive Robotics) </strong> <br> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/chamzas2021-learn-sampling.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> <a href="https://github.com/KavrakiLab/pyre" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a> <a href="https://dx.doi.org/10.1109/ICRA48506.2021.9561104" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">URL</a> <a href="https://youtu.be/cH4_lIjjs58" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">video</a> <a href="https://youtu.be/DP0376NNHQo" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">TALK</a> </div> <div class="abstract hidden"> <p>Earlier work has shown that reusing experience from prior motion planning problems can improve the efficiency of similar, future motion planning queries. However, for robots with many degrees-of-freedom, these methods exhibit poor generalization across different environments and often require large datasets that are impractical to gather. We present SPARK and FLAME , two experience-based frameworks for sampling- based planning applicable to complex manipulators in 3 D environments. Both combine samplers associated with features from a workspace decomposition into a global biased sampling distribution. SPARK decomposes the environment based on exact geometry while FLAME is more general, and uses an octree-based decomposition obtained from sensor data. We demonstrate the effectiveness of SPARK and FLAME on a real and simulated Fetch robot tasked with challenging pick-and- place manipulation problems. Our approaches can be trained incrementally and significantly improve performance with only a handful of examples, generalizing better over diverse tasks and environments as compared to prior approaches.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">chamzas2021-learn-sampling</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chamzas, Constantinos and Kingston, Zachary and Quintero-Pe{\~n}a, Carlos and Shrivastava, Anshumali and E. Kavraki, Lydia}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Robotics and Automation}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Learning Sampling Distributions Using Local 3D Workspace Decompositions for Motion
        Planning in High Dimensions}}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://dx.doi.org/10.1109/ICRA48506.2021.9561104}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICRA48506.2021.9561104}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1283-1289}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge"><a href="https://www.ieee-ras.org/publications/ra-l" target="_blank" rel="external nofollow noopener">RAL</a></abbr> </div> <div id="pairet2021-path-planning-for-manipulation" class="col-sm-10"> <div class="title">Path Planning for Manipulation Using Experience-Driven Random Trees</div> <div class="author"> È. Pairet, <em>C. Chamzas</em>, Y. Petillot, and L. E. Kavraki </div> <div class="periodical"> <em>IEEE Robotics and Automation Letters,</em> 2021 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/pairet2021-path-planning-for-manipulation.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> <a href="https://github.com/ericpairet/ompl/tree/ert_planners" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a> <a href="https://dx.doi.org/10.1109/LRA.2021.3063063" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">URL</a> <a href="https://www.youtube.com/watch?v=kD3A3Xs_psI" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">video</a> </div> <div class="abstract hidden"> <p>Robotic systems may frequently come across similar manipulation planning problems that result in similar motion plans. Instead of planning each problem from scratch, it is preferable to leverage previously computed motion plans, i.e., experiences, to ease the planning. Different approaches have been proposed to exploit prior information on novel task instances. These methods, however, rely on a vast repertoire of experiences and fail when none relates closely to the current problem. Thus, an open challenge is the ability to generalise prior experiences to task instances that do not necessarily resemble the prior. This work tackles the above challenge with the proposition that experiences are "decomposable" and "malleable", i.e., parts of an experience are suitable to relevantly explore the connectivity of the robot-task space even in non-experienced regions. Two new planners result from this insight: experience-driven random trees (ERT) and its bi-directional version ERTConnect. These planners adopt a tree sampling-based strategy that incrementally extracts and modulates parts of a single path experience to compose a valid motion plan. We demonstrate our method on task instances that significantly differ from the prior experiences, and compare with related state-of-the-art experience-based planners. While their repairing strategies fail to generalise priors of tens of experiences, our planner, with a single experience, significantly outperforms them in both success rate and planning time. Our planners are implemented and freely available in the Open Motion Planning Library.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">pairet2021-path-planning-for-manipulation</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Path Planning for Manipulation Using Experience-Driven Random Trees}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2377-3774}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/lra.2021.3063063}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Robotics and Automation Letters}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Institute of Electrical and Electronics Engineers (IEEE)}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pairet, {\`E}ric and Chamzas, Constantinos and Petillot, Yvan R. and E. Kavraki, Lydia}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3295–3302}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://dx.doi.org/10.1109/LRA.2021.3063063}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge"><a href="https://www.ieee-ras.org/conferences-workshops/fully-sponsored/icra" target="_blank" rel="external nofollow noopener">ICRA</a></abbr> </div> <div id="chamzas2019using-local-experiences-for-global-motion-planning" class="col-sm-10"> <div class="title">Using Local Experiences for Global Motion Planning</div> <div class="author"> <em>C. Chamzas</em>, A. Shrivastava, and L. E. Kavraki </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation,</em> 2019 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/chamzas2019using-local-experiences-for-global-motion-planning.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> <a href="https://dx.doi.org/10.1109/ICRA.2019.8794317" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">URL</a> </div> <div class="abstract hidden"> <p>Sampling-based planners are effective in many real-world applications such as robotics manipulation, navigation, and even protein modeling.However, it is often challenging to generate a collision-free path in environments where key areas are hard to sample. In the absence of any prior information, sampling-based planners are forced to explore uniformly or heuristically, which can lead to degraded performance. One way to improve performance is to use prior knowledge of environments to adapt the sampling strategy to the problem at hand. In this work, we decompose the workspace into local primitives, memorizing local experiences by these primitives in the form of local samplers, and store them in a database. We synthesize an efficient global sampler by retrieving local experiences relevant to the given situation. Our method transfers knowledge effectively between diverse environments that share local primitives and speeds up the performance dramatically. Our results show, in terms of solution time, an improvement of multiple orders of magnitude in two traditionally challenging high-dimensional problems compared to state-of-the-art approaches.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">chamzas2019using-local-experiences-for-global-motion-planning</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chamzas, Constantinos and Shrivastava, Anshumali and E. Kavraki, Lydia}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Robotics and Automation}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Using Local Experiences for Global Motion Planning}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{8606--8612}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICRA.2019.8794317}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://dx.doi.org/10.1109/ICRA.2019.8794317}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 ELPIS Lab. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> </body> </html>