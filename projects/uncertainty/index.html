<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Planning Under Uncertainty | Efficient Learning and Planning for Intelligent Systems </title> <meta name="author" content="Constantinos Chamzas"> <meta name="description" content="Learning for Planning Under Uncertainty"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A4%96&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://elpislab.org/projects/uncertainty/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Efficient Learning and Planning for Intelligent Systems </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">Lab </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">People </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/join/">Join </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Planning Under Uncertainty</h1> <p class="post-description">Learning for Planning Under Uncertainty</p> </header> <article> <div class="publications"> <left> <h2><span style="color: var(--global-theme-color)"> Relevant Publications </span></h2> </left> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge"><a href="https://roboticsconference.org/" target="_blank" rel="external nofollow noopener">RSS</a></abbr> </div> <div id="chamzas2023-metapolicy" class="col-sm-10"> <div class="title">Meta-Policy Learning over Plan Ensembles for Robust Articulated Object Manipulation</div> <div class="author"> <em>C. Chamzas</em>, C. Garrett, B. Sundaralingam, L. Kavraki, and D. Fox </div> <div class="periodical"> <em>In RSS 2023: Workshop on Learning for Task and Motion Planning,</em> 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/chamzas2023-metapolicy.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> <a href="https://openreview.net/forum?id=68N8Dj6KVv" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">URL</a> <a href="https://zt-yang.github.io/rss23-l4tamp-workshop/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Website</a> </div> <div class="abstract hidden"> <p>Model-based robotic planning techniques, such as inverse kinematics and motion planning, can endow robots with the ability to perform complex manipulation tasks, such as grasping, object manipulation, and precise placement. However, these methods often assume perfect world knowledge and leverage approximate world models. For example, tasks that involve dynamics such as pushing or pouring are difficult to address with model-based techniques as it is difficult to obtain accurate characterizations of these object dynamics. Additionally, uncertainty in perception prevents them populating an accurate world state estimate. In this work, we propose using a model-based motion planner to build an ensemble of plans under different environment hypotheses. Then, we train a meta-policy to decide online which plan to track based on the current history of observations. By leveraging history, this policy is able to switch ensemble plans to circumvent getting “stuck” in order to complete the task. We tested our method on a 7-DOF Franka-Emika robot pushing a cabinet door in simulation. We demonstrate that a successful meta-policy can be trained to push a door in settings high environment uncertainty all while requiring little data.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">chamzas2023-metapolicy</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chamzas, Constantinos and Garrett, Caelan and Sundaralingam, Balakumar and Kavraki, Lydia E. and Fox, Dieter}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{RSS 2023: Workshop on Learning for Task and Motion Planning}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Meta-Policy Learning over Plan Ensembles for Robust Articulated Object Manipulation}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=68N8Dj6KVv}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge"><a href="https://www.ieee-ras.org/conferences-workshops/fully-sponsored/icra" target="_blank" rel="external nofollow noopener">ICRA</a></abbr> </div> <div id="quintero-chamzas2022-blind" class="col-sm-10"> <div class="title">Human-Guided Motion Planning in Partially Observable Environments</div> <div class="author"> C. Quintero-Peña*, <em>C. Chamzas*</em>, Z. Sun, V. Unhelkar, and L. E. Kavraki </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation,</em> 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/quintero-chamzas2022-blind.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> <a href="https://doi.org/10.1109/ICRA46639.2022.9811893" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">URL</a> <a href="https://youtu.be/m1rc8JNBMAQ" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">video</a> </div> <div class="abstract hidden"> <p>Motion planning is a core problem in robotics, with a range of existing methods aimed to address its diverse set of challenges. However, most existing methods rely on complete knowledge of the robot environment; an assumption that seldom holds true due to inherent limitations of robot perception. To enable tractable motion planning for high-DOF robots under partial observability, we introduce BLIND, an algorithm that leverages human guidance. BLIND utilizes inverse reinforcement learning to derive motion-level guidance from human critiques. The algorithm overcomes the computational challenge of reward learning for high-DOF robots by projecting the robot’s continuous configuration space to a motion-planner-guided discrete task model. The learned reward is in turn used as guidance to generate robot motion using a novel motion planner. We demonstrate BLIND using the Fetch robot an dperform two simulation experiments with partial observability. Our experiments demonstrate that, despite the challenge of partial observability and high dimensionality, BLIND is capable of generating safe robot motion and outperforms baselines on metrics of teaching efficiency, success rate, and path quality.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">quintero-chamzas2022-blind</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Quintero-Pe{\~n}a*, Carlos and Chamzas*, Constantinos and Sun, Zhanyi and Unhelkar, Vaibhav and E. Kavraki, Lydia}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Robotics and Automation}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{7226-7232}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICRA46639.2022.9811893}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Human-Guided Motion Planning in Partially Observable Environments}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1109/ICRA46639.2022.9811893}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge"><a href="https://www.ieee-ras.org/publications/ra-l" target="_blank" rel="external nofollow noopener">RAL</a></abbr> </div> <div id="chamzas2022-motion-bench-maker" class="col-sm-10"> <div class="title">MotionBenchMaker: A Tool to Generate and Benchmark Motion Planning Datasets</div> <div class="author"> <em>C. Chamzas</em>, C. Quintero-Peña, Z. Kingston, A. Orthey, D. Rakita, M. Gleicher, M. Toussaint, and L. E. Kavraki </div> <div class="periodical"> <em>IEEE Robotics and Automation Letters,</em> 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/chamzas2022-motion-bench-maker.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> <a href="https://github.com/KavrakiLab/motion_bench_maker" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a> <a href="https://dx.doi.org/10.1109/LRA.2021.3133603" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">URL</a> <a href="https://youtu.be/t96Py0QX0NI" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">video</a> <a href="https://youtu.be/ggRmKPt7IP8" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">TALK</a> </div> <div class="abstract hidden"> <p>Recently, there has been a wealth of development in motion planning for robotic manipulationnew motion planners are continuously proposed, each with its own unique set of strengths and weaknesses. However, evaluating these new planners is challenging, and researchers often create their own ad-hoc problems for benchmarking, which is time-consuming, prone to bias, and does not directly compare against other state-of-the-art planners. We present MotionBenchMaker, an open-source tool to generate benchmarking datasets for realistic robot manipulation problems. MotionBenchMaker is designed to be an extensible, easy-to-use tool that allows users to both generate datasets and benchmark them by comparing motion planning algorithms. Empirically, we show the benefit of using MotionBenchMaker as a tool to procedurally generate datasets which helps in the fair evaluation of planners. We also present a suite of over 40 prefabricated datasets, with 5 different commonly used robots in 8 environments, to serve as a common ground for future motion planning research.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">chamzas2022-motion-bench-maker</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{MotionBenchMaker: A Tool to Generate and Benchmark Motion Planning Datasets}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{7}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{882–889}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2377-3766}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/LRA.2021.3133603}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Robotics and Automation Letters}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chamzas, Constantinos and Quintero-Pe{\~n}a, Carlos and Kingston, Zachary and Orthey, Andreas and Rakita, Daniel and Gleicher, Michael and Toussaint, Marc and E. Kavraki, Lydia}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://dx.doi.org/10.1109/LRA.2021.3133603}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge"><a href="https://www.ieee-ras.org/conferences-workshops/fully-sponsored/icra" target="_blank" rel="external nofollow noopener">ICRA</a></abbr> </div> <div id="quintero-chamzas2021-motion-planning-in-the-dark" class="col-sm-10"> <div class="title">Motion Planning via Bayesian Learning in the Dark</div> <div class="author"> C. Quintero-Peña*, <em>C. Chamzas*</em>, V. Unhelkar, and L. E. Kavraki </div> <div class="periodical"> <em>In ICRA 2021: Workshop on Machine Learning for Motion Planning,</em> 2021 <br> <strong style="color: var(--global-theme-color)"> (Spotlight) </strong> <br> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/quintero-chamzas2021-motion-planning-in-the-dark.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> <a href="https://sites.google.com/utexas.edu/mlmp-icra2021/home" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">URL</a> <a href="https://youtu.be/33JbcVqnVEM?t=19522" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">TALK</a> </div> <div class="abstract hidden"> <p>Motion planning is a core problem in many applications spanning from robotic manipulation to autonomous driving. Given its importance, several schools of methods have been proposed to address the motion planning problem. However, most existing solutions require complete knowledge of the robot’s environment; an assumption that might not be valid in many real-world applications due to occlusions and inherent limitations of robots’ sensors. Indeed, relatively little emphasis has been placed on developing safe motion planning algorithms that work in partially unknown environments. In this work, we investigate how a human who can observe the robot’s workspace can enable motion planning for a robot with incomplete knowledge of its workspace. We propose a framework that combines machine learning and motion planning to address the challenges of planning motions for high-dimensional robots that learn from human interaction. Our preliminary results indicate that the proposed framework can successfully guide a robot in a partially unknown environment quickly discovering feasible paths.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">quintero-chamzas2021-motion-planning-in-the-dark</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Quintero-Pe{\~n}a*, Carlos and Chamzas*, Constantinos and Unhelkar, Vaibhav and E. Kavraki, Lydia}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ICRA 2021: Workshop on Machine Learning for Motion Planning}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Motion Planning via Bayesian Learning in the Dark}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://sites.google.com/utexas.edu/mlmp-icra2021/home}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Constantinos Chamzas. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> </body> </html>