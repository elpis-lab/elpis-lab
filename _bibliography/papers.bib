---
---

@String { icra   = {IEEE International Conference on Robotics and Automation}}
@String { iros   = {IEEE/RSJ International Conference on Intelligent Robots and Systems}}
@String { iral   = {IEEE Robotics and Automation Letters}}

@inproceedings{kingston2021experience-foliations,
  abstract = {Many robotic manipulation problems are multi-modal—they consist of a discrete set
      of mode families (e.g., whether an object is grasped or placed) each with a continuum of
      parameters (e.g., where exactly an object is grasped). Core to these problems is solving
      single-mode motion plans, i.e., given a mode from a mode family (e.g., a specific grasp),
      find a feasible motion to transition to the next desired mode. Many planners for such
      problems have been proposed, but complex manipulation plans may require prohibitively long
      computation times due to the difficulty of solving these underlying single-mode problems. It
      has been shown that using experience from similar planning queries can significantly improve
      the efficiency of motion planning. However, even though modes from the same family are
      similar, they impose different constraints on the planning problem, and thus experience
      gained in one mode cannot be directly applied to another. We present a new experience-based
      framework, ALEF , for such multi-modal planning problems. ALEF learns using paths from
      single-mode problems from a mode family, and applies this experience to novel modes from the
      same family. We evaluate ALEF on a variety of challenging problems and show a significant
      improvement in the efficiency of sampling-based planners both in isolation and within a
      multi-modal manipulation planner.},
  author = {Kingston, Zachary and Chamzas, Constantinos and E. Kavraki, Lydia},
  booktitle = iros,
  month = sep,
  title = {Using Experience to Improve Constrained Planning on Foliations for Multi-Modal
      Problems},
  year = {2021},
  pdf={kingston2021experience-foliations.pdf}, 
  abbr={IROS},
  bibtex_show={true}
}

@inproceedings{moll2021hyperplan,
  abstract = {Over the years, many motion planning algorithms have been proposed. It is often
      unclear which algorithm might be best suited for a particular class of problems. The problem
      is compounded by the fact that algorithm performance can be highly dependent on parameter
      settings. This paper shows that hyperparameter optimization is an effective tool in both
      algorithm selection and parameter tuning over a given set of motion planning problems. We
      present different loss functions for optimization that capture different notions of
      optimality. The approach is evaluated on a broad range of scenes using two different
      manipulators, a Fetch and a Baxter. We show that optimized planning algorithm performance
      significantly improves upon baseline performance and generalizes broadly in the sense that
      performance improvements carry over to problems that are very different from the ones
      considered during optimization.},
  author = {Moll, Mark and Chamzas, Constantinos and Kingston, Zachary and E. Kavraki, Lydia},
  booktitle = iros, 
  month = sep,
  title = {{HyperPlan}: A Framework for Motion Planning Algorithm Selection and Parameter
      Optimization},
  year = {2021},
  pdf={moll2021hyperplan.pdf}, 
  bibtex_show={true},
  abbr={IROS}
}

@misc{quintero-chamzas2021-motion-planning-in-the-dark,
  abstract = {Motion planning is a core problem in many applications spanning from robotic
      manipulation to autonomous driving. Given its importance, several schools of methods have
      been proposed to address the motion planning problem. However, most existing solutions
      require complete knowledge of the robot's environment; an assumption that might not be valid
      in many real-world applications due to occlusions and inherent limitations of robots'
      sensors. Indeed, relatively little emphasis has been placed on developing safe motion
      planning algorithms that work in partially unknown environments. In this work, we
      investigate how a human who can observe the robot's workspace can enable motion planning for
      a robot with incomplete knowledge of its workspace. We propose a framework that combines
      machine learning and motion planning to address the challenges of planning motions for
      high-dimensional robots that learn from human interaction. Our preliminary results indicate
      that the proposed framework can successfully guide a robot in a partially unknown
      environment quickly discovering feasible paths.},
  author = {Quintero-Pe{\~n}a*, Carlos and Chamzas*, Constantinos and Unhelkar, Vaibhav and E. Kavraki, Lydia},
  booktitle = {ICRA 2021: Workshop on Machine Learning for Motion Planning},
  month = jun,
  title = {Motion Planning via Bayesian Learning in the Dark},
  year = {2021},
  url={https://sites.google.com/utexas.edu/mlmp-icra2021/home},
  pdf={quintero-chamzas2021-motion-planning-in-the-dark.pdf}, 
  url={https://sites.google.com/utexas.edu/mlmp-icra2021/home},
  talk={https://youtu.be/33JbcVqnVEM?t=19522},
  bibtex_show={true},
  note={(Spotlight)}, 
  abbr={ICRA}
}

@inproceedings{chamzas2021-learn-sampling,
  abstract = {Earlier work has shown that reusing experience from prior motion planning problems
      can improve the efficiency of similar, future motion planning queries. However, for robots
      with many degrees-of-freedom, these methods exhibit poor generalization across different
      environments and often require large datasets that are impractical to gather. We present
      SPARK and FLAME , two experience-based frameworks for sampling- based planning applicable to
      complex manipulators in 3 D environments. Both combine samplers associated with features
      from a workspace decomposition into a global biased sampling distribution. SPARK decomposes
      the environment based on exact geometry while FLAME is more general, and uses an
      octree-based decomposition obtained from sensor data. We demonstrate the effectiveness of
      SPARK and FLAME on a real and simulated Fetch robot tasked with challenging pick-and- place
      manipulation problems. Our approaches can be trained incrementally and significantly improve
      performance with only a handful of examples, generalizing better over diverse tasks and
      environments as compared to prior approaches.},
  author = {Chamzas, Constantinos and Kingston, Zachary and Quintero-Pe{\~n}a, Carlos and Shrivastava, Anshumali and E. Kavraki, Lydia },
  booktitle = icra, 
  month = jun,
  title = {{Learning Sampling Distributions Using Local 3D Workspace Decompositions for Motion
      Planning in High Dimensions}},
  year = {2021},
  note = {(Top-4 finalist for best paper in Cognitive Robotics)},
  pdf={chamzas2021-learn-sampling.pdf}, 
  url = {https://dx.doi.org/10.1109/ICRA48506.2021.9561104},
  doi={10.1109/ICRA48506.2021.9561104},
  pages={1283-1289},
  code={https://github.com/KavrakiLab/pyre}, 
  talk={https://youtu.be/DP0376NNHQo},
  video={https://youtu.be/cH4_lIjjs58},
  selected={true},
  abbr={ICRA},
  bibtex_show={true}
}

@article{pairet2021-path-planning-for-manipulation,
  abstract = {Robotic systems may frequently come across similar manipulation planning problems
      that result in similar motion plans. Instead of planning each problem from scratch, it is
      preferable to leverage previously computed motion plans, i.e., experiences, to ease the
      planning. Different approaches have been proposed to exploit prior information on novel task
      instances. These methods, however, rely on a vast repertoire of experiences and fail when
      none relates closely to the current problem. Thus, an open challenge is the ability to
      generalise prior experiences to task instances that do not necessarily resemble the prior.
      This work tackles the above challenge with the proposition that experiences are
      “decomposable” and “malleable”, i.e., parts of an experience are suitable to
      relevantly explore the connectivity of the robot-task space even in non-experienced regions.
      Two new planners result from this insight: experience-driven random trees (ERT) and its
      bi-directional version ERTConnect. These planners adopt a tree sampling-based strategy that
      incrementally extracts and modulates parts of a single path experience to compose a valid
      motion plan. We demonstrate our method on task instances that significantly differ from the
      prior experiences, and compare with related state-of-the-art experience-based planners.
      While their repairing strategies fail to generalise priors of tens of experiences, our
      planner, with a single experience, significantly outperforms them in both success rate and
      planning time. Our planners are implemented and freely available in the Open Motion Planning
      Library.},
  title = {Path Planning for Manipulation Using Experience-Driven Random Trees},
  volume = {6},
  issn = {2377-3774},
  doi = {10.1109/lra.2021.3063063},
  number = {2},
  journal = iral, 
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  author = {Pairet, {\`E}ric and Chamzas, Constantinos and Petillot, Yvan R. and E. Kavraki, Lydia},
  year = {2021},
  month = apr,
  pages = {3295–3302},
  url = {https://dx.doi.org/10.1109/LRA.2021.3063063},
  pdf = {pairet2021-path-planning-for-manipulation.pdf},
  code = {https://github.com/ericpairet/ompl/tree/ert_planners}, 
  bibtex_show={true},
  abbr = {RAL}
}

@inproceedings{chamzas2021-cMinMax,
   abstract={
During the last years, the emerging field of Augmented Virtual Reality (AR-VR) has seen tremendous growth. At the same time there is a trend to develop low cost high-quality AR systems where computing power is in demand. Feature points are extensively used in these real-time frame-rate and 3D applications, therefore efficient high-speed feature detectors are necessary. Corners are such special features and often are used as the first step in the marker alignment in Augmented Reality (AR). Corners are also used in image registration and recognition, tracking, SLAM, robot path finding and 2D or 3D object detection and retrieval. Therefore there is a large number of corner detection algorithms but most of them are too computationally intensive for use in real-time applications of any complexity. Many times the border of the image is a convex polygon. For this special, but quite common case, we have developed a specific algorithm, cMinMax. The proposed algorithm is faster, approximatel y by a factor of 5 compared to the widely used Harris Corner Detection algorithm. In addition is highly parallelizable. The algorithm is suitable for the fast registration of markers in augmented reality systems and in applications where a computationally efficient real time feature detector is necessary. The algorithm can also be extended to N-dimensional polyhedrons.},
   title={cMinMax: A Fast Algorithm to Find the Corners of an N-dimensional Convex Polytope},
   isbn={9789897584886},
   doi={10.5220/0010259002290236},
   booktitle={16th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications},
   publisher={SCITEPRESS - Science and Technology Publications},
   author={Chamzas, Dimitrios and Chamzas, Constantinos and Moustakas, Konstantinos},
   year={2021},
   url={https://dx.doi.org/10.5220/0010259002290236},
   pdf={chamzas2020-cminmax.pdf}, 
   video={https://www.youtube.com/watch?v=y4e7_5uWy6o},
   talk={https://www.youtube.com/watch?v=Ug313Nf-S-A},
   bibtex_show={true},
   abbr = {GRAPP}
}

@misc{chamzas2020rep-learning,
  bibtex_show={true},
  abstract = {Representation learning allows planning actions directly from raw observations.
      Variational Autoencoders (VAEs) and their modifications are often used to learn latent state
      representations from high-dimensional observations such as images of the scene. This
      approach uses the similarity between observations in the space of images as a proxy for
      estimating similarity between the underlying states of the system. We argue that, despite
      some successful implementations, this approach is not applicable in the general case where
      observations contain task-irrelevant factors of variation. We compare different methods to
      learn latent representations for a box stacking task and show that models with weak
      supervision such as Siamese networks with a simple contrastive loss produce more useful
      representations than traditionally used autoencoders for the final downstream manipulation
      task.},
  author = {Chamzas*, Constantinos and Lippi*, Martina and Welle*, Michael C. and Varava, Anastasiia and Alessandro, Marino and E. Kavraki, Lydia and Kragic, Danica},
  booktitle = {NeurIPS, 3rd Robot Learning Workshop: Grounding Machine Learning Development in the
      Real World},
  title = {State Representations in Robotics: Identifying Relevant Factors of Variation using Weak
      Supervision},
  year = {2020},
  month = dec,
  url = {https://www.robot-learning.ml/2020/},
  pdf={chamzas2020rep-learning.pdf}, 
  website = {https://state-representation.github.io/web/},
  code = {https://github.com/State-Representation/code},
  abbr = {NeurIPS}
}

@inproceedings{chamzas2019using-local-experiences-for-global-motion-planning,
      abstract = {Sampling-based planners are effective in many real-world applications such as
          robotics manipulation, navigation, and even protein modeling.However, it is often
          challenging to generate a collision-free path in environments where key areas are hard to
          sample. In the absence of any prior information, sampling-based planners are forced to
      explore uniformly or heuristically, which can lead to degraded performance. One way to
      improve performance is to use prior knowledge of environments to adapt the sampling strategy
      to the problem at hand. In this work, we decompose the workspace into local primitives,
      memorizing local experiences by these primitives in the form of local samplers, and store
      them in a database. We synthesize an efficient global sampler by retrieving local
      experiences relevant to the given situation. Our method transfers knowledge effectively
      between diverse environments that share local primitives and speeds up the performance
      dramatically. Our results show, in terms of solution time, an improvement of multiple orders
      of magnitude in two traditionally challenging high-dimensional problems compared to
      state-of-the-art approaches.},
  author = {Chamzas, Constantinos and Shrivastava, Anshumali and E. Kavraki, Lydia},
  booktitle = icra, 
  month = may,
  title = {Using Local Experiences for Global Motion Planning},
  year = {2019},
  pages = {8606--8612},
  doi = {10.1109/ICRA.2019.8794317},
  url = {https://dx.doi.org/10.1109/ICRA.2019.8794317},
  pdf = {chamzas2019using-local-experiences-for-global-motion-planning.pdf},
  bibtex_show = {true},
  selected= {true},
  abbr = {ICRA}
}
